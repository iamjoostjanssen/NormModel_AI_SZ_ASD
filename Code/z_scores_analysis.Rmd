

```{r}
library(tidyr)
library(openxlsx)
library(rcompanion)
library(dplyr)
library(coin)
library(effectsize)
library(esc)
library(Rtsne)
library(fpc)
library(cluster)
library(ggplot2)
library(ggpubr)
```



```{r}
# Read Data:

z_scores_li_rom <- read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI/z_scores_noAGES/S90_RomeroGarciaSymm_test_warp_3order_noAGES_SEX_ID_dcode_site_scan_z.csv')
z_scores_sch <- read.csv('/data_J/scripts/imaging_data/normative_modeling/Schaefer2018/AI/z_scores_noAGES/S90_Schaefer2018_test_warp_3order_noAGES_SEX_ID_dcode_site_scan_z.csv')
z_scores_trad_rom <- read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/S90_RomeroGarciaSymm_AI_trad_test_warp_3order_noAGES_SEX_ID_dcode_site_scan_z.csv', sep=",")

z_scores_li_rom <- z_scores_li_rom[, !(names(z_scores_li_rom) %in% c("site", "scanner"))]
z_scores_sch <- z_scores_sch[, !(names(z_scores_sch) %in% c("site", "scanner"))]
z_scores_trad_rom <- z_scores_trad_rom[, !(names(z_scores_trad_rom) %in% c("site", "scanner"))]


z_scores_trad_mean <- read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/S90_mean_test_trad_warp_3order_noAGES_ID_dcode_site_scan_z.csv', sep=",")
z_scores_trad_mean <- z_scores_trad_mean[, !(names(z_scores_trad_mean) %in% c("site", "scanner"))]
z_scores_cortex <- read.csv('/data_J/scripts/imaging_data/normative_modeling/cortex_z_scores/S90_RomeroGarciaSymm_cortex_test_warp_3order_SEX_ID_dcode_site_scan_z.csv') 
z_scores_cortex <- subset(z_scores_cortex, select = -scanner)

#Keep only males:
z_scores_trad_mean_males <- subset(z_scores_trad_mean, sex == 1)
z_scores_trad_rom_males <- subset(z_scores_trad_rom, sex == 1)

```

```{r}

#Create data frames for each group containing the number of supra- and infra-threshold values, their respective percentages, and the total count. (This code is just for mean_ai_trad or z_cortex because it has only one column (instead of several regions))

unique_dcodes <- unique(z_scores_cortex$dcode)

for (dcode_value in unique_dcodes) {
  subset_df <- z_scores_cortex[z_scores_cortex$dcode == dcode_value, ]
  
  # Remove irrelevant columns
  subset_df <- subset_df[, !names(subset_df) %in% c('ID', 'dcode', 'sex', 'site'), drop = FALSE]
  
  # To store results
  counts_df <- data.frame(
    Region = character(),  
    Supra = numeric(),     
    Infra = numeric(),    
    Total = numeric(),     
    Perc_Infra = numeric(),
    Perc_Supra = numeric() 
  )
  
  # Rename only column
  col_name <- "z_cortex"
  
  # Count supra and infra vals
  supra_count <- sum(subset_df[, col_name] > 1.96, na.rm = TRUE)
  infra_count <- sum(subset_df[, col_name] < -1.96, na.rm = TRUE)
  
  total_count <- nrow(subset_df)
  

  perc_infra <- (infra_count / total_count) * 100
  perc_supra <- (supra_count / total_count) * 100
  
  # Add results
  counts_df <- rbind(counts_df, data.frame(
    Region = col_name,
    Supra = supra_count,
    Infra = infra_count,
    Total = total_count,
    Perc_Infra = perc_infra,
    Perc_Supra = perc_supra
  ))
  

  df_name <- paste0("df_", as.character(dcode_value))
  
  assign(df_name, counts_df)
}

```

```{r}
#Save dataframes:

#write.csv(df_1, file = '/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_HC_cortex.csv' , row.names = FALSE)
#write.csv(df_2, file = '/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_ASD_cortex.csv' , row.names = FALSE)
#write.csv(df_3, file = '/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_SZ_cortex.csv' , row.names = FALSE)
```

```{r}

#Create data frames for each group containing the number of supra- and infra-threshold values, their respective percentages, and the total count for each region.


# Get unique values in the dcode column
unique_dcodes <- unique(z_scores_trad_rom_males$dcode) #CHANGE IT FOR EACH FILE!

for (dcode_value in unique_dcodes) {
  # Perform for each dcode
  subset_df <- z_scores_trad_rom_males[z_scores_trad_rom_males$dcode == dcode_value, ] #CHANGE IT FOR EACH FILE!
  
  # Remove irrelevant columns 
  subset_df <- subset_df[, !(names(subset_df) %in% c('ID', 'dcode', 'sex'))]
  
  # Create the output df
  counts_df <- data.frame(
    Region = character(),  
    Supra = numeric(),     
    Infra = numeric(),    
    Total = numeric(),     
    Prop_Infra = numeric(),
    Prop_Supra = numeric() 
  )
  
  # Iterate through eache region
  for (col_name in names(subset_df)) {
    # Cunt supra and infra values
    supra_count <- sum(subset_df[, col_name] > 1.96, na.rm = TRUE)
    infra_count <- sum(subset_df[, col_name] < -1.96, na.rm = TRUE)
    
    # Total subjects
    total_count <- nrow(subset_df)
    
    # Calculate percentage
    perc_infra <- (infra_count / total_count)*100
    perc_supra <- (supra_count / total_count)*100
    
    # Add all columns
    counts_df <- rbind(counts_df, c(col_name, supra_count, infra_count, total_count, perc_infra, perc_supra))
  }
  
  # Rename columns
  colnames(counts_df) <- c("Region", "Supra", "Infra", "Total", "Perc_Infra", "Perc_Supra")
  
  # Final df name for each dcode
  df_name <- paste0("df_", as.character(dcode_value))
  
  assign(df_name, counts_df)
}


#Save them
#write.csv(df_1, file = '/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_HC_trad_romero_males.csv' , row.names = FALSE)
#write.csv(df_2, file = '/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_ASD_trad_romero_males.csv' , row.names = FALSE)
#write.csv(df_3, file = '/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_SZ_trad_romero_males.csv' , row.names = FALSE)
```

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    COMPARE PROPORTIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

```{r}
#Read files:
prop_HC_trad_romero <-  read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_HC_trad_romero.csv', sep=",")
prop_ASD_trad_romero <-  read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_ASD_trad_romero.csv', sep=",")
prop_SZ_trad_romero <-  read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_SZ_trad_romero.csv', sep=",")
```


```{r}

# This code performs chi-square tests (traditional and permuted) to compare the frequencies 
# of "Supra" and "Infra" values between two groups across multiple regions.
# 
# Output:
# - `supra_results_df`: Contains regions, p-values (traditional and permuted), and FDR-corrected p-values for "Supra".
# - `infra_results_df`: Contains the same information for "Infra".


compare_frequencies <- function(df1, df2, region, category) {
  df1_region <- df1[df1$Region == region, ]
  df2_region <- df2[df2$Region == region, ]

  if (category == "Supra") {
    a1 <- sum(df1_region$Supra)
    a2 <- sum(df1_region$Total) 
    b1 <- sum(df2_region$Supra)
    b2 <- sum(df2_region$Total) 
  } else if (category == "Infra") {
    a1 <- sum(df1_region$Infra)
    a2 <- sum(df1_region$Total) 
    b1 <- sum(df2_region$Infra)
    b2 <- sum(df2_region$Total) 
  }
  
  hc_category <- a1 / a2
  fep_category <- b1 / b2
  
  list(region = region, hc_category = hc_category, fep_category = fep_category)
}

# Create a dataframe to store the test results for Supra
supra_results_df <- data.frame(region = character(), 
                             p_val = numeric(), 
                             p_val_corrected = numeric(), 
                             perm_p_val = numeric(), 
                             perm_p_val_corrected = numeric(), 
                             stringsAsFactors = FALSE)

# Create a dataframe to store the test results for Infra
infra_results_df <- data.frame(region = character(), 
                               p_val = numeric(), 
                               p_val_corrected = numeric(), 
                               perm_p_val = numeric(), 
                               perm_p_val_corrected = numeric(), 
                               stringsAsFactors = FALSE)


# Obtain unique regions
unique_regions <- unique(prop_HC_trad_romero$Region) #change it for each file

for (region in unique_regions) {
  df1_region <- prop_HC_trad_romero[prop_HC_trad_romero$Region == region, ] #change it for the corresponding group HC
  df2_region <- prop_ASD_trad_romero[prop_ASD_trad_romero$Region == region, ] #change it for the corresponding group condition
  # Obtain specific values for each group
  a1 <- sum(df1_region$Supra)  # Values of Supra 
  a2 <- sum(df1_region$Total)  # Total
  
  b1 <- sum(df2_region$Supra)  # Values of Supra
  b2 <- sum(df2_region$Total)  # Total

  # Contingency table for Supra
  permudata_supra <- rbind(
    data.frame(x = rep(c("SupraYES", "SupraNO"), c(a1, a2 - a1)), y = "Freq1"),
    data.frame(x = rep(c("SupraYES", "SupraNO"), c(b1, b2 - b1)), y = "Freq2")
  )

  permudata_supra$x <- factor(permudata_supra$x)
  permudata_supra$y <- factor(permudata_supra$y)
  
  # Traditional chi-square test for Supra
  trad_result_supra <- chisq.test(permudata_supra$x, permudata_supra$y, correct = F)
  p_val_trad_supra <- trad_result_supra$p.value

  # Permuted chi-square test for Supra
  set.seed(1234)
  result_per_supra <- chisq_test(y ~ x, data = permudata_supra, distribution = approximate(nresample = 9999))
  perm_p_val_supra <- pvalue(result_per_supra)[1]

  # Store the p-values in the results dataframe for Supra
  supra_results_df <- rbind(supra_results_df, data.frame(region = region, p_val = p_val_trad_supra, perm_p_val = perm_p_val_supra))
  
  # Obtain specific values for each group 
  c1 <- sum(df1_region$Infra)  # Values of Infra 
  c2 <- sum(df1_region$Total)  # Total
  
  d1 <- sum(df2_region$Infra)  # Values of Infra
  d2 <- sum(df2_region$Total)  # Total

  # Contingency table for Infra
  permudata_infra <- rbind(
    data.frame(x = rep(c("InfraYES", "InfraNO"), c(c1, c2 - c1)), y = "Freq1"),
    data.frame(x = rep(c("InfraYES", "InfraNO"), c(d1, d2 - d1)), y = "Freq2")
  )

  permudata_infra$x <- factor(permudata_infra$x)
  permudata_infra$y <- factor(permudata_infra$y)
  
  # Traditional chi-square test for Infra
  trad_result_infra <- chisq.test(permudata_infra$x, permudata_infra$y, correct = F)
  p_val_trad_infra <- trad_result_infra$p.value

  # Permuted chi-square test for Infra
  set.seed(1234)
  result_per_infra <- chisq_test(y ~ x, data = permudata_infra, distribution = approximate(nresample = 9999))
  perm_p_val_infra <- pvalue(result_per_infra)[1]

  # Store the p-values in the results dataframe for Infra
  infra_results_df <- rbind(infra_results_df, data.frame(region = region, p_val = p_val_trad_infra, perm_p_val = perm_p_val_infra))
}

# Apply FDR correction to p-values
supra_results_df$p_val_corrected <- p.adjust(supra_results_df$p_val, method = "fdr")
supra_results_df$perm_p_val_corrected <- p.adjust(supra_results_df$perm_p_val, method = "fdr")

infra_results_df$p_val_corrected <- p.adjust(infra_results_df$p_val, method = "fdr")
infra_results_df$perm_p_val_corrected <- p.adjust(infra_results_df$perm_p_val, method = "fdr")

```
```{r}
infra_results_df
```


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 Chi-square for mean & cortex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

```{r}
prop_HC_mean_trad <-  read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_HC_mean_Al_trad.csv', sep=",")
prop_ASD_mean_trad <-  read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_ASD_mean_Al_trad.csv', sep=",")
prop_SZ_mean_trad <-  read.csv('/data_J/scripts/imaging_data/normative_modeling/RomeroGarciaSymm/AI_trad/z_scores_noAGES/proportion/proportion_SZ_mean_Al_trad.csv', sep=",")
```

```{r}


# Function to calculate Cohen's d from chi-square test statistic
calculate_cohens_d <- function(chi_squared, total_n) {
  effect_size <- esc_chisq(chisq = chi_squared, totaln = total_n, es.type = "d")
  return(effect_size$es)
}

# Function to perform chi-square tests (traditional and permuted) and calculate proportions
perform_chi_square_test <- function(group_data, group_labels) {
  # Prepare data for chi-square test
  permudata <- rbind(
    data.frame(x = rep(c(paste0(group_labels, "YES"), paste0(group_labels, "NO")), 
                     c(group_data$Infra, group_data$Total - group_data$Infra)), y = "HC"),
    data.frame(x = rep(c(paste0(group_labels, "YES"), paste0(group_labels, "NO")), 
                     c(group_data$Supra, group_data$Total - group_data$Supra)), y = "ASD")
  )
  permudata$x <- factor(permudata$x)
  permudata$y <- factor(permudata$y)

  # Traditional chi-square test
  trad_result <- chisq.test(permudata$x, permudata$y, correct = FALSE)
  p_val_trad <- trad_result$p.value
  effect_size <- calculate_cohens_d(trad_result$statistic, sum(trad_result$observed))

  # Permuted chi-square test
  set.seed(1234)
  result_per <- chisq_test(y ~ x, data = permudata, distribution = approximate(nresample = 9999))
  perm_p_val <- pvalue(result_per)[1]

  # Calculate proportions
  HC_data <- permudata[permudata$y == "HC", ]
  proportion_HC <- sum(HC_data$x == paste0(group_labels, "YES")) / nrow(HC_data)

  ASD_data <- permudata[permudata$y == "ASD", ]
  proportion_ASD <- sum(ASD_data$x == paste0(group_labels, "YES")) / nrow(ASD_data)

  # Return results
  return(list(
    p_val_trad = p_val_trad,
    perm_p_val = perm_p_val,
    effect_size = effect_size,
    proportion_HC = proportion_HC,
    proportion_ASD = proportion_ASD
  ))
}

infra_results <- perform_chi_square_test(prop_HC_mean_trad, "Infra")
supra_results <- perform_chi_square_test(prop_HC_mean_trad, "Supra")

# Combine results into a data frame
results_df <- data.frame(
  Test = c("Infra", "Supra"),
  p_val = c(infra_results$p_val_trad, supra_results$p_val_trad),
  perm_p_val = c(infra_results$perm_p_val, supra_results$perm_p_val),
  effect_size = c(infra_results$effect_size, supra_results$effect_size),
  proportion_HC = c(infra_results$proportion_HC, supra_results$proportion_HC),
  proportion_ASD = c(infra_results$proportion_ASD, supra_results$proportion_ASD)
)

# Repeat for HC vs SZ

```




%%%%%%%%%%%%%%%%%%
      TSNE
%%%%%%%%%%%%%%%%%%


```{r}
# t-SNE for dimensionality reduction and PAM clustering to determine optimal clusters (k) and visualize results.  
# It generates density, scatter, and distribution plots grouped by diagnosis (HCtest, ASD, SZ) and clustering results, saving multi-panel plots.

outdir <- '/data_J/scripts/imaging_data/figures/FINAL_FIGURES/TSNE/'

# List of datasets to process:
datasets <- list(
  z_scores_li_rom = z_scores_li_rom,
  z_scores_sch = z_scores_sch,
  z_scores_trad_rom = z_scores_trad_rom,
  z_scores_trad_rom_males = z_scores_trad_rom_males
)

# Loop through each dataset
for (dataset_name in names(datasets)) {
  z_scores <- datasets[[dataset_name]]
  z <- z_scores[, !names(z_scores) %in% c("ID", "site", "scanner", "sex")]

  sm.tsne <- Rtsne(as.matrix(z[, -1]), check_duplicates = FALSE, pca = TRUE, perplexity = 30, theta = 0.5, dims = 2)
  t.dist <- as.matrix(dist(sm.tsne$Y))
  pamk.best <- pamk(t.dist)
  optimal_k <- pamk.best$nc

  # Section C: PAM clustering with optimal k
  pam.res <- pam(t.dist, k = optimal_k)
  groups <- as.data.frame(pam.res$clustering)
  test <- cbind(as.data.frame(sm.tsne$Y), groups)
  colnames(test) <- c("V1", "V2", "Cl")
  test$Cl <- as.factor(test$Cl)
  
  dens1 <- ggplot(test, aes(x = V1, y = V2)) +
    stat_density2d(aes(fill = Cl, alpha = after_stat(level)), geom = "polygon") +
    theme_void() +
    theme(legend.position = "none") +
    guides(fill = guide_legend(title = NULL))

  l1 <- ggplot(test, aes(V1, V2)) + 
    geom_point(aes(color = Cl)) +
    theme_void() +
    theme(legend.position = "none") +
    scale_color_discrete(name = "")
  
  t1 <- ggplot(test, aes(V1, fill = Cl)) + 
    geom_density(alpha = 0.5) +
    theme_void() +
    theme(legend.position = "bottom", legend.justification = 'center',
          legend.background = element_rect(fill = "white", linewidth = 0.5, linetype = "solid", colour = "black")) +
    scale_fill_discrete(name = "")

  l2 <- ggplot(test, aes(V2, fill = Cl)) + 
    geom_density(alpha = 0.5) +
    theme_void() +
    theme(legend.position = "none") +
    coord_flip() +
    scale_fill_discrete(name = "")

  # Panel B: Colored by 'dcode' (diagnosis)
  test <- cbind(as.data.frame(sm.tsne$Y), z_scores$dcode)
  colnames(test) <- c("V1", "V2", "Group")

  # Replace diagnosis numbers with labels
  test$Group <- as.factor(test$Group)
  levels(test$Group) <- c("HCtest", "ASD", "SZ")

  # Reorder Group levels to appear in the desired order: ASD, SZ, HCtest
  test$Group <- factor(test$Group, levels = c("ASD", "SZ", "HCtest"))

  # 2D density plot for the diagnoses with custom colors
  dens2 <- ggplot(test, aes(x = V1, y = V2)) +
    stat_density2d(aes(fill = Group, alpha = after_stat(level)), geom = "polygon") +
    theme_void() +
    theme(legend.position = "none") +
    scale_fill_manual(values = c("HCtest" = "#F3B61F", "ASD" = "#0C3D87", "SZ" = "#7CACF6"), name = "")

  l3 <- ggplot(test, aes(V1, V2)) + 
    geom_point(aes(color = Group)) +
    theme_void() +
    theme(legend.position = "none") +
    scale_color_manual(values = c("HCtest" = "#F3B61F", "ASD" = "#0C3D87", "SZ" = "#7CACF6"), name = "")

  t2 <- ggplot(test, aes(V1, fill = Group)) + 
    geom_density(alpha = 0.5) +
    theme_void() +
    theme(legend.position = "bottom", legend.justification = 'center',
          legend.background = element_rect(fill = "white", linewidth = 0.5, linetype = "solid", colour = "black")) +
    scale_fill_manual(values = c("HCtest" = "#F3B61F", "ASD" = "#0C3D87", "SZ" = "#7CACF6"), name = "")

  l4 <- ggplot(test, aes(V2, fill = Group)) + 
    geom_density(alpha = 0.5) +
    coord_flip() +
    theme_void() +
    theme(legend.position = "none") +
    scale_fill_manual(values = c("HCtest" = "#F3B61F", "ASD" = "#0C3D87", "SZ" = "#7CACF6"), name = "")

  # Section C2: PAM clustering with k = 3
  pam.res_k3 <- pam(t.dist, k = 3)
  groups_k3 <- as.data.frame(pam.res_k3$clustering)
  test_k3 <- cbind(as.data.frame(sm.tsne$Y), groups_k3)
  colnames(test_k3) <- c("V1", "V2", "Cl")
  test_k3$Cl <- as.factor(test_k3$Cl)

  dens3 <- ggplot(test_k3, aes(x = V1, y = V2)) +
    stat_density2d(aes(fill = Cl, alpha = after_stat(level)), geom = "polygon") +
    theme_void() +
    theme(legend.position = "none") +
    guides(fill = guide_legend(title = NULL))

  l5 <- ggplot(test_k3, aes(V1, V2)) + 
    geom_point(aes(color = Cl)) +
    theme_void() +
    theme(legend.position = "none") +
    scale_color_discrete(name = "")
  
  t3 <- ggplot(test_k3, aes(V1, fill = Cl)) + 
    geom_density(alpha = 0.5) +
    theme_void() +
    theme(legend.position = "bottom", legend.justification = 'center',
          legend.background = element_rect(fill = "white", linewidth = 0.5, linetype = "solid", colour = "black")) +
    scale_fill_discrete(name = "")

  l6 <- ggplot(test_k3, aes(V2, fill = Cl)) + 
    geom_density(alpha = 0.5) +
    theme_void() +
    theme(legend.position = "none") +
    coord_flip() +
    scale_fill_discrete(name = "")

  # Combine all plots into the final plot with C, B, and C2
  tsnePlot <- ggarrange(
    ggarrange(t1, dens1, l1, l2, ncol = 2, nrow = 2, labels = c(""), widths = c(3, 0.9), heights = c(1.5, 3)),
    ggarrange(t3, dens3, l5, l6, ncol = 2, nrow = 2, labels = c(""), widths = c(3, 0.9), heights = c(1.5, 3)),
    ggarrange(t2, dens2, l3, l4, ncol = 2, nrow = 2, labels = c(""), widths = c(3, 0.9), heights = c(1.5, 3)),
    ncol = 3, nrow = 1, labels = c("A1", "A2", "B")
  )

  # Save the final plot (uncomment this if you want to save to a file)
  # savename <- paste0(outdir, "tsne_3sections_", optimal_k, "_", dataset_name, ".pdf")
  # pdf(savename, width = 16, height = 4)
  print(tsnePlot)
  # dev.off() # Uncomment if you want to save the plot to a file
}

```





